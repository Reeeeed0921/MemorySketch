# PGGç³»ç»ŸCSVæ–‡æ¡£æ¥å£å®Œæ•´ä½¿ç”¨è¯´æ˜

## ğŸ¯ **åŠŸèƒ½æ¦‚è¿°**

PGGæƒ…æ„Ÿè®°å¿†ç”Ÿæˆç³»ç»Ÿç°å·²å®Œæ•´é›†æˆCSVæ–‡æ¡£å¤„ç†åŠŸèƒ½ï¼Œæä¾›äº†**13ä¸ªä¸“ä¸šåŒ–CSVå¤„ç†æ¥å£**ï¼Œæ”¯æŒCSVæ–‡ä»¶çš„å¯¼å…¥ã€å¯¼å‡ºã€åˆ†æã€è½¬æ¢ã€åˆå¹¶ã€æ‹†åˆ†ã€éªŒè¯ç­‰å…¨æ–¹ä½æ“ä½œã€‚

## ğŸ“Š **æ”¯æŒçš„CSVæ•°æ®æ ¼å¼**

### 1. å›å¿†è®°å½•æ ¼å¼ (memories)
```csv
id,user_id,user_input,memory_text,image_url,primary_emotion,confidence,emotion_scores,created_at
memory_001,user_123,ä»Šå¤©å¤©æ°”å¾ˆå¥½,ä»Šå¤©å¤©æ°”å¾ˆå¥½è®©æˆ‘æƒ³èµ·äº†æ˜¥å¤©,image1.jpg,happy,0.85,"{""happy"": 0.85}",2024-01-01T12:00:00
```

### 2. æƒ…æ„Ÿæ•°æ®æ ¼å¼ (emotions)
```csv
id,user_id,text,primary_emotion,confidence,emotion_scores,valence,arousal,dominance,created_at
emotion_001,user_123,ä»Šå¤©å¿ƒæƒ…å¾ˆå¥½,happy,0.90,"{""happy"": 0.90}",0.8,0.6,0.7,2024-01-01T12:00:00
```

### 3. è€äººæ•°æ®æ ¼å¼ (elderly_data)
```csv
id,user_id,text,primary_emotion,confidence,age,gender,age_group,keywords_matched,keyword_count,elderly_specific_health,elderly_specific_family,elderly_specific_loneliness,elderly_specific_nostalgia,ai_suggestions,created_at,updated_at
elderly_001,user_123,æƒ³å¿µå­™å­,nostalgia,0.85,70,å¥³,senior,"å­™å­,æƒ³å¿µ",2,0,1,1,1,"å¤šä¸å®¶äººè”ç³»",2024-01-01T12:00:00,2024-01-01T12:00:00
```

### 4. ä¼ æ„Ÿå™¨æ•°æ®æ ¼å¼ (sensor_data)
```csv
sensor_id,sensor_type,device_id,user_id,value,unit,timestamp,quality,metadata
sensor_001,heart_rate,device_123,user_456,72,bpm,2024-01-01T12:00:00,good,"{""battery_level"": 85}"
```

### 5. ç”¨æˆ·ç»Ÿè®¡æ ¼å¼ (user_statistics)
```csv
user_id,total_memories,emotion_distribution,most_common_emotion,first_memory_date,last_memory_date,emotional_trend,updated_at
user_123,50,"{""happy"": 30, ""sad"": 20}",happy,2024-01-01T12:00:00,2024-01-10T12:00:00,"{""trend"": ""positive""}",2024-01-01T12:00:00
```

### 6. å…³é”®è¯åˆ†ææ ¼å¼ (keywords)
```csv
keyword,frequency,category,emotional_correlation,usage_context,first_appearance,last_appearance,trend
å­™å­,15,å®¶åº­å…³ç³»,"{""happy"": 12, ""nostalgia"": 3}",å®¶åº­æƒ…æ„Ÿ,2024-01-01T12:00:00,2024-01-10T12:00:00,0.2
è¡€å‹,8,å¥åº·å…³é”®è¯,"{""worry"": 6, ""neutral"": 2}",å¥åº·çŠ¶å†µ,2024-01-02T12:00:00,2024-01-09T12:00:00,-0.1
å¹¿åœºèˆ,5,ç¤¾äº¤æ´»åŠ¨,"{""happy"": 4, ""social"": 1}",ç¤¾äº¤å¨±ä¹,2024-01-03T12:00:00,2024-01-08T12:00:00,0.1
```

## ğŸš€ **å®Œæ•´APIæ¥å£æ¸…å•**

### 1. æ•°æ®å¯¼å‡ºæ¥å£
- **`POST /csv/export`** - å¯¼å‡ºæ•°æ®ä¸ºCSVæ ¼å¼
- **`GET /csv/download/<filename>`** - ä¸‹è½½CSVæ–‡ä»¶

### 2. æ•°æ®å¯¼å…¥æ¥å£
- **`POST /csv/import`** - å¯¼å…¥CSVæ–‡ä»¶æ•°æ®

### 3. æ–‡ä»¶åˆ†ææ¥å£
- **`POST /csv/analyze`** - åˆ†æCSVæ–‡ä»¶ç»“æ„
- **`POST /csv/statistics`** - è·å–CSVæ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯
- **`POST /csv/validate`** - éªŒè¯CSVæ–‡ä»¶æ•°æ®

### 4. æ–‡ä»¶å¤„ç†æ¥å£
- **`POST /csv/convert`** - è½¬æ¢CSVæ ¼å¼
- **`POST /csv/merge`** - åˆå¹¶å¤šä¸ªCSVæ–‡ä»¶
- **`POST /csv/split`** - æ‹†åˆ†CSVæ–‡ä»¶

### 5. æ¨¡æ¿ç®¡ç†æ¥å£
- **`POST /csv/template`** - åˆ›å»ºCSVæ¨¡æ¿
- **`GET /csv/formats`** - è·å–æ”¯æŒçš„CSVæ ¼å¼

### 6. å…³é”®è¯åˆ†ææ¥å£
- **`POST /csv/keywords/analyze`** - åˆ†æCSVæ•°æ®ä¸­çš„å…³é”®è¯
- **`POST /csv/keywords/export`** - å¯¼å‡ºå…³é”®è¯åˆ†æç»“æœä¸ºCSV
- **`GET /csv/keywords/config`** - è·å–å…³é”®è¯é…ç½®

## ğŸ“‹ **è¯¦ç»†æ¥å£è¯´æ˜**

### 1. CSVæ•°æ®å¯¼å‡º - POST /csv/export

**åŠŸèƒ½**: å°†æ•°æ®å¯¼å‡ºä¸ºCSVæ ¼å¼æ–‡ä»¶

**è¯·æ±‚æ ¼å¼**:
```bash
POST http://localhost:5000/csv/export
Content-Type: application/json

{
  "data": [
    {
      "id": "memory_001",
      "user_id": "user_123",
      "user_input": "ä»Šå¤©å¤©æ°”å¾ˆå¥½",
      "memory_text": "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œè®©æˆ‘æƒ³èµ·äº†æ˜¥å¤©",
      "primary_emotion": "happy",
      "confidence": 0.85
    }
  ],
  "type": "memories",
  "filename": "memories_export.csv",
  "options": {
    "include_headers": true,
    "encoding": "utf-8",
    "delimiter": ",",
    "custom_fields": ["id", "user_id", "user_input", "primary_emotion"]
  }
}
```

**è¯·æ±‚å‚æ•°**:
- `data`: è¦å¯¼å‡ºçš„æ•°æ®æ•°ç»„ï¼ˆå¿…å¡«ï¼‰
- `type`: æ•°æ®ç±»å‹ï¼Œæ”¯æŒ: memories, emotions, elderly_data, sensor_data, user_statistics, general
- `filename`: è‡ªå®šä¹‰æ–‡ä»¶åï¼ˆå¯é€‰ï¼‰
- `options`: å¯¼å‡ºé€‰é¡¹
  - `include_headers`: æ˜¯å¦åŒ…å«è¡¨å¤´ï¼ˆé»˜è®¤trueï¼‰
  - `encoding`: æ–‡ä»¶ç¼–ç ï¼ˆé»˜è®¤utf-8ï¼‰
  - `delimiter`: å­—æ®µåˆ†éš”ç¬¦ï¼ˆé»˜è®¤é€—å·ï¼‰
  - `custom_fields`: è‡ªå®šä¹‰å­—æ®µåˆ—è¡¨

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "message": "CSVå¯¼å‡ºæˆåŠŸ",
  "data": {
    "file_path": "/path/to/memories_export_20240101_120000.csv",
    "filename": "memories_export_20240101_120000.csv",
    "file_size": 1024,
    "record_count": 1,
    "fields": ["id", "user_id", "user_input", "primary_emotion"],
    "export_type": "memories",
    "encoding": "utf-8",
    "delimiter": ",",
    "created_at": "2024-01-01T12:00:00"
  }
}
```

### 2. CSVæ•°æ®å¯¼å…¥ - POST /csv/import

**åŠŸèƒ½**: ä»CSVæ–‡ä»¶å¯¼å…¥æ•°æ®

**è¯·æ±‚æ ¼å¼**:
```bash
POST http://localhost:5000/csv/import
Content-Type: multipart/form-data

# è¡¨å•æ•°æ®
file: [CSVæ–‡ä»¶]
type: memories
encoding: utf-8
delimiter: ,
skip_header: true
validate_data: true
```

**è¯·æ±‚å‚æ•°**:
- `file`: è¦å¯¼å…¥çš„CSVæ–‡ä»¶ï¼ˆå¿…å¡«ï¼‰
- `type`: æ•°æ®ç±»å‹ï¼ˆé»˜è®¤generalï¼‰
- `encoding`: æ–‡ä»¶ç¼–ç ï¼ˆé»˜è®¤utf-8ï¼‰
- `delimiter`: å­—æ®µåˆ†éš”ç¬¦ï¼ˆé»˜è®¤é€—å·ï¼‰
- `skip_header`: æ˜¯å¦è·³è¿‡è¡¨å¤´ï¼ˆé»˜è®¤trueï¼‰
- `validate_data`: æ˜¯å¦éªŒè¯æ•°æ®ï¼ˆé»˜è®¤trueï¼‰

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "message": "CSVå¯¼å…¥æˆåŠŸ",
  "data": {
    "data": [
      {
        "id": "memory_001",
        "user_id": "user_123",
        "user_input": "ä»Šå¤©å¤©æ°”å¾ˆå¥½",
        "primary_emotion": "happy"
      }
    ],
    "total_rows": 1,
    "success_count": 1,
    "error_count": 0,
    "errors": [],
    "file_size": 1024,
    "import_type": "memories",
    "encoding": "utf-8",
    "delimiter": ",",
    "processed_at": "2024-01-01T12:00:00"
  }
}
```

### 3. CSVæ–‡ä»¶ç»“æ„åˆ†æ - POST /csv/analyze

**åŠŸèƒ½**: åˆ†æCSVæ–‡ä»¶çš„ç»“æ„å’Œå­—æ®µç±»å‹

**è¯·æ±‚æ ¼å¼**:
```bash
POST http://localhost:5000/csv/analyze
Content-Type: multipart/form-data

# è¡¨å•æ•°æ®
file: [CSVæ–‡ä»¶]
encoding: utf-8
delimiter: ,
sample_size: 100
```

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "message": "CSVæ–‡ä»¶åˆ†ææˆåŠŸ",
  "data": {
    "file_size": 1024,
    "total_rows": 100,
    "headers": ["id", "user_id", "text", "emotion"],
    "field_count": 4,
    "field_analysis": {
      "id": {
        "type": "string",
        "null_count": 0,
        "unique_values": 100,
        "sample_values": ["memory_001", "memory_002"]
      },
      "confidence": {
        "type": "float",
        "null_count": 5,
        "unique_values": 50,
        "sample_values": [0.85, 0.92, 0.78]
      }
    },
    "sample_data": [
      {"id": "memory_001", "user_id": "user_123", "text": "ä»Šå¤©å¾ˆå¼€å¿ƒ", "emotion": "happy"}
    ],
    "analyzed_at": "2024-01-01T12:00:00"
  }
}
```

### 4. CSVæ¨¡æ¿åˆ›å»º - POST /csv/template

**åŠŸèƒ½**: åˆ›å»ºCSVæ¨¡æ¿æ–‡ä»¶

**è¯·æ±‚æ ¼å¼**:
```bash
POST http://localhost:5000/csv/template
Content-Type: application/json

{
  "type": "memories",
  "include_examples": true,
  "custom_fields": ["id", "user_id", "text", "emotion"]
}
```

**è¯·æ±‚å‚æ•°**:
- `type`: æ¨¡æ¿ç±»å‹ï¼ˆå¿…å¡«ï¼‰
- `include_examples`: æ˜¯å¦åŒ…å«ç¤ºä¾‹æ•°æ®ï¼ˆé»˜è®¤trueï¼‰
- `custom_fields`: è‡ªå®šä¹‰å­—æ®µåˆ—è¡¨ï¼ˆå¯é€‰ï¼‰

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "message": "CSVæ¨¡æ¿åˆ›å»ºæˆåŠŸ",
  "data": {
    "file_path": "/path/to/memories_template_20240101_120000.csv",
    "filename": "memories_template_20240101_120000.csv",
    "template_type": "memories",
    "fields": ["id", "user_id", "user_input", "memory_text", "primary_emotion"],
    "field_count": 5,
    "include_examples": true,
    "example_count": 1,
    "created_at": "2024-01-01T12:00:00"
  }
}
```

### 5. CSVæ ¼å¼è½¬æ¢ - POST /csv/convert

**åŠŸèƒ½**: è½¬æ¢CSVæ•°æ®æ ¼å¼

**è¯·æ±‚æ ¼å¼**:
```bash
POST http://localhost:5000/csv/convert
Content-Type: multipart/form-data

# è¡¨å•æ•°æ®
file: [CSVæ–‡ä»¶]
from_type: general
to_type: memories
mapping_rules: {"target_field": "source_field"}
```

**è¯·æ±‚å‚æ•°**:
- `file`: è¦è½¬æ¢çš„CSVæ–‡ä»¶ï¼ˆå¿…å¡«ï¼‰
- `from_type`: æºæ•°æ®ç±»å‹ï¼ˆå¿…å¡«ï¼‰
- `to_type`: ç›®æ ‡æ•°æ®ç±»å‹ï¼ˆå¿…å¡«ï¼‰
- `mapping_rules`: å­—æ®µæ˜ å°„è§„åˆ™ï¼ˆå¯é€‰ï¼ŒJSONæ ¼å¼ï¼‰

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "message": "CSVæ ¼å¼è½¬æ¢æˆåŠŸ",
  "data": {
    "input_file": "/path/to/input.csv",
    "output_file": "/path/to/converted_input.csv",
    "from_type": "general",
    "to_type": "memories",
    "converted_records": 100,
    "export_info": {
      "filename": "converted_input.csv",
      "file_size": 2048,
      "record_count": 100
    }
  }
}
```

### 6. CSVæ–‡ä»¶åˆå¹¶ - POST /csv/merge

**åŠŸèƒ½**: åˆå¹¶å¤šä¸ªCSVæ–‡ä»¶

**è¯·æ±‚æ ¼å¼**:
```bash
POST http://localhost:5000/csv/merge
Content-Type: multipart/form-data

# è¡¨å•æ•°æ®
files: [CSVæ–‡ä»¶1, CSVæ–‡ä»¶2, ...]
merge_type: union
remove_duplicates: true
key_fields: ["id", "user_id"]
```

**è¯·æ±‚å‚æ•°**:
- `files`: è¦åˆå¹¶çš„CSVæ–‡ä»¶åˆ—è¡¨ï¼ˆå¿…å¡«ï¼Œè‡³å°‘2ä¸ªï¼‰
- `merge_type`: åˆå¹¶ç±»å‹ï¼ˆunion, intersection, left_join, inner_joinï¼‰
- `remove_duplicates`: æ˜¯å¦ç§»é™¤é‡å¤è¡Œï¼ˆé»˜è®¤trueï¼‰
- `key_fields`: åˆå¹¶å…³é”®å­—æ®µï¼ˆJSONæ•°ç»„æ ¼å¼ï¼‰

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "message": "CSVæ–‡ä»¶åˆå¹¶æˆåŠŸ",
  "data": {
    "input_files": ["/path/to/file1.csv", "/path/to/file2.csv"],
    "output_file": "/path/to/merged_20240101_120000.csv",
    "merge_type": "union",
    "total_input_records": 200,
    "merged_records": 180,
    "file_info": [
      {"file_path": "/path/to/file1.csv", "record_count": 100, "errors": 0},
      {"file_path": "/path/to/file2.csv", "record_count": 100, "errors": 0}
    ]
  }
}
```

### 7. CSVæ–‡ä»¶æ‹†åˆ† - POST /csv/split

**åŠŸèƒ½**: æ‹†åˆ†CSVæ–‡ä»¶

**è¯·æ±‚æ ¼å¼**:
```bash
POST http://localhost:5000/csv/split
Content-Type: multipart/form-data

# è¡¨å•æ•°æ®
file: [CSVæ–‡ä»¶]
split_by: rows
split_size: 1000
split_field: user_id
```

**è¯·æ±‚å‚æ•°**:
- `file`: è¦æ‹†åˆ†çš„CSVæ–‡ä»¶ï¼ˆå¿…å¡«ï¼‰
- `split_by`: æ‹†åˆ†æ–¹å¼ï¼ˆrows, field, sizeï¼‰
- `split_size`: æ‹†åˆ†å¤§å°ï¼ˆé»˜è®¤1000ï¼‰
- `split_field`: æ‹†åˆ†å­—æ®µï¼ˆå½“split_byä¸ºfieldæ—¶ï¼‰

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "message": "CSVæ–‡ä»¶æ‹†åˆ†æˆåŠŸ",
  "data": {
    "input_file": "/path/to/input.csv",
    "output_dir": "/path/to/split_20240101_120000/",
    "split_by": "rows",
    "split_size": 1000,
    "total_records": 5000,
    "split_files": [
      {
        "file_path": "/path/to/split_20240101_120000/chunk_1.csv",
        "filename": "chunk_1.csv",
        "record_count": 1000
      },
      {
        "file_path": "/path/to/split_20240101_120000/chunk_2.csv",
        "filename": "chunk_2.csv",
        "record_count": 1000
      }
    ],
    "file_count": 5
  }
}
```

### 8. CSVæ–‡ä»¶éªŒè¯ - POST /csv/validate

**åŠŸèƒ½**: éªŒè¯CSVæ–‡ä»¶æ•°æ®

**è¯·æ±‚æ ¼å¼**:
```bash
POST http://localhost:5000/csv/validate
Content-Type: multipart/form-data

# è¡¨å•æ•°æ®
file: [CSVæ–‡ä»¶]
validation_type: memories
custom_rules: {"field": "rule"}
```

**è¯·æ±‚å‚æ•°**:
- `file`: è¦éªŒè¯çš„CSVæ–‡ä»¶ï¼ˆå¿…å¡«ï¼‰
- `validation_type`: éªŒè¯ç±»å‹ï¼ˆé»˜è®¤generalï¼‰
- `custom_rules`: è‡ªå®šä¹‰éªŒè¯è§„åˆ™ï¼ˆå¯é€‰ï¼ŒJSONæ ¼å¼ï¼‰

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "message": "CSVæ–‡ä»¶éªŒè¯å®Œæˆ",
  "data": {
    "file_path": "/path/to/input.csv",
    "validation_type": "memories",
    "total_rows": 1000,
    "valid_rows": 950,
    "invalid_rows": 50,
    "validation_rate": 0.95,
    "errors": [
      {
        "row": 25,
        "error": "ç¼ºå°‘å¿…å¡«å­—æ®µ: user_id",
        "data": {"id": "memory_025", "text": "ä»Šå¤©å¾ˆå¼€å¿ƒ"}
      }
    ],
    "validated_at": "2024-01-01T12:00:00"
  }
}
```

### 9. CSVæ–‡ä»¶ç»Ÿè®¡ - POST /csv/statistics

**åŠŸèƒ½**: è·å–CSVæ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯

**è¯·æ±‚æ ¼å¼**:
```bash
POST http://localhost:5000/csv/statistics
Content-Type: multipart/form-data

# è¡¨å•æ•°æ®
file: [CSVæ–‡ä»¶]
```

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "message": "CSVæ–‡ä»¶ç»Ÿè®¡åˆ†æå®Œæˆ",
  "data": {
    "file_path": "/path/to/input.csv",
    "file_size": 10240,
    "row_count": 1000,
    "column_count": 5,
    "columns": ["id", "user_id", "text", "emotion", "confidence"],
    "data_types": {
      "id": "object",
      "user_id": "object",
      "text": "object",
      "emotion": "object",
      "confidence": "float64"
    },
    "memory_usage": 50000,
    "null_counts": {
      "id": 0,
      "user_id": 0,
      "text": 5,
      "emotion": 10,
      "confidence": 20
    },
    "describe": {
      "confidence": {
        "count": 980,
        "mean": 0.85,
        "std": 0.12,
        "min": 0.45,
        "max": 0.98
      }
    },
    "analyzed_at": "2024-01-01T12:00:00"
  }
}
```

### 10. è·å–æ”¯æŒæ ¼å¼ - GET /csv/formats

**åŠŸèƒ½**: è·å–ç³»ç»Ÿæ”¯æŒçš„CSVæ ¼å¼

**è¯·æ±‚æ ¼å¼**:
```bash
GET http://localhost:5000/csv/formats
```

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "data": {
    "supported_formats": ["memories", "emotions", "elderly_data", "sensor_data", "user_statistics"],
    "format_details": {
      "memories": {
        "fields": ["id", "user_id", "user_input", "memory_text", "image_url", "primary_emotion", "confidence", "emotion_scores", "created_at"],
        "required": ["user_id", "user_input", "memory_text"],
        "types": {
          "confidence": "float",
          "created_at": "datetime",
          "emotion_scores": "dict"
        }
      }
    }
  },
  "message": "æˆåŠŸè·å–æ”¯æŒçš„CSVæ ¼å¼"
}
```

### 11. æ–‡ä»¶ä¸‹è½½ - GET /csv/download/<filename>

**åŠŸèƒ½**: ä¸‹è½½CSVæ–‡ä»¶

**è¯·æ±‚æ ¼å¼**:
```bash
GET http://localhost:5000/csv/download/memories_export_20240101_120000.csv
```

**å“åº”**: ç›´æ¥è¿”å›CSVæ–‡ä»¶å†…å®¹

### 12. å…³é”®è¯åˆ†æ - POST /csv/keywords/analyze

**åŠŸèƒ½**: åˆ†æCSVæ•°æ®ä¸­çš„å…³é”®è¯

**è¯·æ±‚æ ¼å¼**:
```json
{
  "data": [
    {
      "text": "ä»Šå¤©å­™å­æ¥çœ‹æˆ‘äº†ï¼Œå¾ˆå¼€å¿ƒ",
      "user_id": "user_123",
      "primary_emotion": "happy"
    }
  ],
  "format": "general"
}
```

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "data": {
    "keyword_analysis": {
      "total_keywords": 98,
      "most_common_keywords": {"å­™å­": 5, "å¼€å¿ƒ": 3},
      "matched_records": 1,
      "unmatched_records": 0,
      "average_keywords_per_record": 2.0
    },
    "text_analysis": {
      "total_records": 1,
      "records_with_keywords": 1,
      "keyword_density": 100.0
    },
    "elderly_specific_insights": {
      "family_keywords": {"å­™å­": 5},
      "health_keywords": {},
      "loneliness_keywords": {},
      "social_keywords": {}
    }
  },
  "message": "å…³é”®è¯åˆ†æå®Œæˆï¼Œå…±åˆ†æ1æ¡è®°å½•ï¼Œå‘ç°2ä¸ªä¸åŒå…³é”®è¯"
}
```

### 13. å…³é”®è¯å¯¼å‡º - POST /csv/keywords/export

**åŠŸèƒ½**: å¯¼å‡ºå…³é”®è¯åˆ†æç»“æœä¸ºCSVæ–‡ä»¶

**è¯·æ±‚æ ¼å¼**:
```json
{
  "data": [
    {
      "text": "ä»Šå¤©å­™å­æ¥çœ‹æˆ‘äº†ï¼Œå¾ˆå¼€å¿ƒ",
      "user_id": "user_123",
      "primary_emotion": "happy"
    }
  ],
  "format": "general",
  "filename": "keywords_analysis_20240101.csv"
}
```

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "data": {
    "file_path": "./storage/keywords_analysis_20240101.csv",
    "filename": "keywords_analysis_20240101.csv",
    "processed_records": 1,
    "keywords_found": 2,
    "download_url": "/csv/download/keywords_analysis_20240101.csv"
  },
  "message": "å…³é”®è¯åˆ†æç»“æœå¯¼å‡ºæˆåŠŸ"
}
```

### 14. å…³é”®è¯é…ç½® - GET /csv/keywords/config

**åŠŸèƒ½**: è·å–å…³é”®è¯é…ç½®ä¿¡æ¯

**è¯·æ±‚æ ¼å¼**:
```bash
GET http://localhost:5000/csv/keywords/config
```

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "data": {
    "keywords": ["å­™å­", "å­™å¥³", "é€€ä¼‘", "å…»è€", "è€ä¼´", "..."],
    "total_keywords": 98,
    "keyword_threshold": 2,
    "min_age": 60,
    "categories": {
      "åŸºç¡€å…³é”®è¯": ["å­™å­", "å­™å¥³", "é€€ä¼‘", "å…»è€", "è€ä¼´", "å„¿åª³", "å¥³å©¿", "çœ‹ç—…", "ä½“æ£€"],
      "å®¶åº­å…³ç³»": ["é‡å­™", "é‡å­™å¥³", "å¤–å­™", "..."],
      "ç”Ÿæ´»ç›¸å…³": ["è€èŠ±é•œ", "æ‹æ–", "è¡€å‹", "..."],
      "ç¤¾äº¤ä¸æ´»åŠ¨": ["å¹¿åœºèˆ", "å¤ªæ", "æ™¨ç»ƒ", "..."],
      "æƒ…æ„ŸçŠ¶æ€": ["å­¤ç‹¬", "å¯‚å¯", "æƒ³å¿µ", "..."],
      "ç”Ÿæ´»çŠ¶æ€": ["ç‹¬å±…", "ç©ºå·¢", "ç…§é¡¾", "..."]
    }
  },
  "message": "å…³é”®è¯é…ç½®è·å–æˆåŠŸï¼Œå…±98ä¸ªå…³é”®è¯"
}
```

## ğŸ¯ **å®é™…ä½¿ç”¨ç¤ºä¾‹**

### 1. Pythonå®¢æˆ·ç«¯ç¤ºä¾‹

```python
import requests
import json

class CSVAPIClient:
    def __init__(self, base_url="http://localhost:5000"):
        self.base_url = base_url
        self.session = requests.Session()
    
    def export_data(self, data, export_type="general", filename=None, options=None):
        """å¯¼å‡ºæ•°æ®ä¸ºCSV"""
        url = f"{self.base_url}/csv/export"
        payload = {
            "data": data,
            "type": export_type,
            "filename": filename,
            "options": options or {}
        }
        
        response = self.session.post(url, json=payload)
        return response.json()
    
    def import_csv(self, file_path, import_type="general", encoding="utf-8"):
        """å¯¼å…¥CSVæ–‡ä»¶"""
        url = f"{self.base_url}/csv/import"
        
        with open(file_path, 'rb') as f:
            files = {'file': f}
            data = {
                'type': import_type,
                'encoding': encoding,
                'skip_header': 'true',
                'validate_data': 'true'
            }
            
            response = self.session.post(url, files=files, data=data)
            return response.json()
    
    def analyze_csv(self, file_path, encoding="utf-8", sample_size=100):
        """åˆ†æCSVæ–‡ä»¶ç»“æ„"""
        url = f"{self.base_url}/csv/analyze"
        
        with open(file_path, 'rb') as f:
            files = {'file': f}
            data = {
                'encoding': encoding,
                'sample_size': str(sample_size)
            }
            
            response = self.session.post(url, files=files, data=data)
            return response.json()
    
    def create_template(self, template_type, include_examples=True, custom_fields=None):
        """åˆ›å»ºCSVæ¨¡æ¿"""
        url = f"{self.base_url}/csv/template"
        payload = {
            "type": template_type,
            "include_examples": include_examples,
            "custom_fields": custom_fields
        }
        
        response = self.session.post(url, json=payload)
        return response.json()
    
    def download_file(self, filename, save_path=None):
        """ä¸‹è½½CSVæ–‡ä»¶"""
        url = f"{self.base_url}/csv/download/{filename}"
        response = self.session.get(url)
        
        if response.status_code == 200:
            if save_path:
                with open(save_path, 'wb') as f:
                    f.write(response.content)
                return save_path
            else:
                return response.content
        else:
            return response.json()

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    client = CSVAPIClient()
    
    # 1. å¯¼å‡ºæ•°æ®
    sample_data = [
        {
            "id": "memory_001",
            "user_id": "user_123",
            "user_input": "ä»Šå¤©å¤©æ°”å¾ˆå¥½",
            "memory_text": "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œè®©æˆ‘æƒ³èµ·äº†æ˜¥å¤©",
            "primary_emotion": "happy",
            "confidence": 0.85
        }
    ]
    
    export_result = client.export_data(
        data=sample_data,
        export_type="memories",
        filename="test_export.csv"
    )
    print("å¯¼å‡ºç»“æœ:", export_result)
    
    # 2. åˆ›å»ºæ¨¡æ¿
    template_result = client.create_template(
        template_type="memories",
        include_examples=True
    )
    print("æ¨¡æ¿åˆ›å»ºç»“æœ:", template_result)
    
    # 3. åˆ†æCSVæ–‡ä»¶
    if template_result['success']:
        template_filename = template_result['data']['filename']
        # ä¸‹è½½æ¨¡æ¿æ–‡ä»¶
        client.download_file(template_filename, "template.csv")
        
        # åˆ†ææ¨¡æ¿æ–‡ä»¶
        analysis_result = client.analyze_csv("template.csv")
        print("åˆ†æç»“æœ:", analysis_result)
    
    # 4. å¯¼å…¥CSVæ–‡ä»¶
    import_result = client.import_csv("template.csv", "memories")
    print("å¯¼å…¥ç»“æœ:", import_result)
```

### 2. JavaScriptå®¢æˆ·ç«¯ç¤ºä¾‹

```javascript
class CSVAPIClient {
    constructor(baseUrl = 'http://localhost:5000') {
        this.baseUrl = baseUrl;
    }
    
    async exportData(data, exportType = 'general', filename = null, options = {}) {
        const response = await fetch(`${this.baseUrl}/csv/export`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify({
                data: data,
                type: exportType,
                filename: filename,
                options: options
            })
        });
        
        return await response.json();
    }
    
    async importCSV(file, importType = 'general', encoding = 'utf-8') {
        const formData = new FormData();
        formData.append('file', file);
        formData.append('type', importType);
        formData.append('encoding', encoding);
        formData.append('skip_header', 'true');
        formData.append('validate_data', 'true');
        
        const response = await fetch(`${this.baseUrl}/csv/import`, {
            method: 'POST',
            body: formData
        });
        
        return await response.json();
    }
    
    async analyzeCSV(file, encoding = 'utf-8', sampleSize = 100) {
        const formData = new FormData();
        formData.append('file', file);
        formData.append('encoding', encoding);
        formData.append('sample_size', sampleSize.toString());
        
        const response = await fetch(`${this.baseUrl}/csv/analyze`, {
            method: 'POST',
            body: formData
        });
        
        return await response.json();
    }
    
    async createTemplate(templateType, includeExamples = true, customFields = null) {
        const response = await fetch(`${this.baseUrl}/csv/template`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify({
                type: templateType,
                include_examples: includeExamples,
                custom_fields: customFields
            })
        });
        
        return await response.json();
    }
    
    async downloadFile(filename) {
        const response = await fetch(`${this.baseUrl}/csv/download/${filename}`);
        
        if (response.ok) {
            const blob = await response.blob();
            const url = window.URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = filename;
            document.body.appendChild(a);
            a.click();
            window.URL.revokeObjectURL(url);
            document.body.removeChild(a);
            return true;
        } else {
            return await response.json();
        }
    }
    
    async getSupportedFormats() {
        const response = await fetch(`${this.baseUrl}/csv/formats`);
        return await response.json();
    }
}

// ä½¿ç”¨ç¤ºä¾‹
const client = new CSVAPIClient();

// å¯¼å‡ºæ•°æ®ç¤ºä¾‹
const sampleData = [
    {
        id: 'memory_001',
        user_id: 'user_123',
        user_input: 'ä»Šå¤©å¤©æ°”å¾ˆå¥½',
        memory_text: 'ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œè®©æˆ‘æƒ³èµ·äº†æ˜¥å¤©',
        primary_emotion: 'happy',
        confidence: 0.85
    }
];

client.exportData(sampleData, 'memories', 'test_export.csv')
    .then(result => console.log('å¯¼å‡ºç»“æœ:', result))
    .catch(error => console.error('å¯¼å‡ºé”™è¯¯:', error));

// æ–‡ä»¶ä¸Šä¼ å¤„ç†ç¤ºä¾‹
document.getElementById('fileInput').addEventListener('change', async (event) => {
    const file = event.target.files[0];
    if (file && file.name.endsWith('.csv')) {
        try {
            const analysisResult = await client.analyzeCSV(file);
            console.log('åˆ†æç»“æœ:', analysisResult);
            
            const importResult = await client.importCSV(file, 'memories');
            console.log('å¯¼å…¥ç»“æœ:', importResult);
        } catch (error) {
            console.error('å¤„ç†é”™è¯¯:', error);
        }
    }
});
```

### 3. å‘½ä»¤è¡Œå·¥å…·ç¤ºä¾‹

```bash
#!/bin/bash

# CSV API å‘½ä»¤è¡Œå·¥å…·
CSV_API_BASE="http://localhost:5000"

# å¯¼å‡ºæ•°æ®
export_csv() {
    local data_file=$1
    local export_type=$2
    local filename=$3
    
    curl -X POST "${CSV_API_BASE}/csv/export" \
        -H "Content-Type: application/json" \
        -d @"$data_file" \
        -o "export_result.json"
    
    echo "å¯¼å‡ºç»“æœå·²ä¿å­˜åˆ° export_result.json"
}

# å¯¼å…¥CSVæ–‡ä»¶
import_csv() {
    local file_path=$1
    local import_type=$2
    
    curl -X POST "${CSV_API_BASE}/csv/import" \
        -F "file=@$file_path" \
        -F "type=$import_type" \
        -F "encoding=utf-8" \
        -F "skip_header=true" \
        -F "validate_data=true" \
        -o "import_result.json"
    
    echo "å¯¼å…¥ç»“æœå·²ä¿å­˜åˆ° import_result.json"
}

# åˆ†æCSVæ–‡ä»¶
analyze_csv() {
    local file_path=$1
    
    curl -X POST "${CSV_API_BASE}/csv/analyze" \
        -F "file=@$file_path" \
        -F "encoding=utf-8" \
        -F "sample_size=100" \
        -o "analysis_result.json"
    
    echo "åˆ†æç»“æœå·²ä¿å­˜åˆ° analysis_result.json"
}

# åˆ›å»ºæ¨¡æ¿
create_template() {
    local template_type=$1
    
    curl -X POST "${CSV_API_BASE}/csv/template" \
        -H "Content-Type: application/json" \
        -d "{\"type\": \"$template_type\", \"include_examples\": true}" \
        -o "template_result.json"
    
    echo "æ¨¡æ¿åˆ›å»ºç»“æœå·²ä¿å­˜åˆ° template_result.json"
}

# ä¸‹è½½æ–‡ä»¶
download_csv() {
    local filename=$1
    local save_path=${2:-$filename}
    
    curl -X GET "${CSV_API_BASE}/csv/download/$filename" \
        -o "$save_path"
    
    echo "æ–‡ä»¶å·²ä¸‹è½½åˆ° $save_path"
}

# ä½¿ç”¨ç¤ºä¾‹
case $1 in
    "export")
        export_csv "$2" "$3" "$4"
        ;;
    "import")
        import_csv "$2" "$3"
        ;;
    "analyze")
        analyze_csv "$2"
        ;;
    "template")
        create_template "$2"
        ;;
    "download")
        download_csv "$2" "$3"
        ;;
    *)
        echo "ä½¿ç”¨æ–¹æ³•:"
        echo "  $0 export <data_file> <type> <filename>"
        echo "  $0 import <csv_file> <type>"
        echo "  $0 analyze <csv_file>"
        echo "  $0 template <type>"
        echo "  $0 download <filename> [save_path]"
        ;;
esac
```

## ğŸ”§ **é«˜çº§åŠŸèƒ½**

### 1. æ‰¹é‡å¤„ç†å·¥ä½œæµ

```python
def batch_process_workflow(file_list, output_dir):
    """æ‰¹é‡å¤„ç†CSVæ–‡ä»¶å·¥ä½œæµ"""
    client = CSVAPIClient()
    
    # 1. åˆ†ææ‰€æœ‰æ–‡ä»¶
    analysis_results = []
    for file_path in file_list:
        result = client.analyze_csv(file_path)
        analysis_results.append(result)
    
    # 2. éªŒè¯æ–‡ä»¶æ ¼å¼
    valid_files = []
    for i, result in enumerate(analysis_results):
        if result['success'] and result['data']['field_count'] > 0:
            valid_files.append(file_list[i])
    
    # 3. åˆå¹¶æ–‡ä»¶
    if len(valid_files) > 1:
        # ä½¿ç”¨APIåˆå¹¶æ–‡ä»¶
        merge_result = merge_csv_files(valid_files)
        print(f"åˆå¹¶ç»“æœ: {merge_result}")
    
    # 4. æ‹†åˆ†å¤§æ–‡ä»¶
    for file_path in valid_files:
        file_size = os.path.getsize(file_path)
        if file_size > 10 * 1024 * 1024:  # 10MB
            split_result = split_csv_file(file_path, 1000)
            print(f"æ‹†åˆ†ç»“æœ: {split_result}")
    
    return True
```

### 2. æ•°æ®è´¨é‡æ£€æŸ¥

```python
def data_quality_check(file_path):
    """æ•°æ®è´¨é‡æ£€æŸ¥"""
    client = CSVAPIClient()
    
    # 1. åˆ†ææ–‡ä»¶ç»“æ„
    analysis = client.analyze_csv(file_path)
    
    # 2. ç»Ÿè®¡åˆ†æ
    statistics = client.get_statistics(file_path)
    
    # 3. éªŒè¯æ•°æ®
    validation = client.validate_csv(file_path)
    
    # 4. è´¨é‡æŠ¥å‘Š
    quality_report = {
        'file_path': file_path,
        'total_rows': analysis['data']['total_rows'],
        'valid_rows': validation['data']['valid_rows'],
        'data_quality_score': validation['data']['validation_rate'],
        'null_percentage': sum(statistics['data']['null_counts'].values()) / (analysis['data']['total_rows'] * analysis['data']['field_count']),
        'recommendations': []
    }
    
    # 5. ç”Ÿæˆå»ºè®®
    if quality_report['data_quality_score'] < 0.8:
        quality_report['recommendations'].append("æ•°æ®è´¨é‡è¾ƒä½ï¼Œå»ºè®®è¿›è¡Œæ•°æ®æ¸…æ´—")
    
    if quality_report['null_percentage'] > 0.1:
        quality_report['recommendations'].append("ç©ºå€¼è¾ƒå¤šï¼Œå»ºè®®æ£€æŸ¥æ•°æ®å®Œæ•´æ€§")
    
    return quality_report
```

## ğŸ¯ **æœ€ä½³å®è·µ**

### 1. å¤§æ–‡ä»¶å¤„ç†
- ä½¿ç”¨åˆ†å—å¤„ç†é¿å…å†…å­˜æº¢å‡º
- ä¼˜å…ˆä½¿ç”¨æ–‡ä»¶æ‹†åˆ†åŠŸèƒ½å¤„ç†å¤§æ–‡ä»¶
- è®¾ç½®åˆé€‚çš„sample_sizeè¿›è¡Œåˆ†æ

### 2. æ•°æ®éªŒè¯
- å§‹ç»ˆå¼€å¯æ•°æ®éªŒè¯
- ä¸ºä¸åŒæ•°æ®ç±»å‹è®¾ç½®åˆé€‚çš„éªŒè¯è§„åˆ™
- å¤„ç†éªŒè¯é”™è¯¯å¹¶æä¾›ç”¨æˆ·å‹å¥½çš„é”™è¯¯ä¿¡æ¯

### 3. æ€§èƒ½ä¼˜åŒ–
- ä½¿ç”¨åˆé€‚çš„ç¼–ç æ ¼å¼ï¼ˆUTF-8æ¨èï¼‰
- é€‰æ‹©é€‚å½“çš„åˆ†éš”ç¬¦
- æ‰¹é‡å¤„ç†æ—¶æ§åˆ¶å¹¶å‘æ•°é‡

### 4. é”™è¯¯å¤„ç†
- æ£€æŸ¥APIå“åº”çŠ¶æ€
- å¤„ç†æ–‡ä»¶æ ¼å¼é”™è¯¯
- æä¾›å›é€€æœºåˆ¶

## ğŸ“ **æŠ€æœ¯æ”¯æŒ**

### å¸¸è§é—®é¢˜
1. **æ–‡ä»¶ç¼–ç é—®é¢˜**: ç¡®ä¿ä½¿ç”¨UTF-8ç¼–ç 
2. **å†…å­˜ä¸è¶³**: å¯¹å¤§æ–‡ä»¶ä½¿ç”¨æ‹†åˆ†åŠŸèƒ½
3. **æ•°æ®æ ¼å¼ä¸åŒ¹é…**: ä½¿ç”¨æ ¼å¼è½¬æ¢åŠŸèƒ½
4. **éªŒè¯å¤±è´¥**: æ£€æŸ¥å¿…å¡«å­—æ®µå’Œæ•°æ®ç±»å‹

### è°ƒè¯•å·¥å…·
```bash
# æ£€æŸ¥æ”¯æŒçš„æ ¼å¼
curl http://localhost:5000/csv/formats

# åˆ›å»ºæµ‹è¯•æ¨¡æ¿
curl -X POST http://localhost:5000/csv/template \
  -H 'Content-Type: application/json' \
  -d '{"type": "memories", "include_examples": true}'
```

---

ğŸ‰ **PGGç³»ç»ŸCSVæ–‡æ¡£æ¥å£å·²å®Œæ•´å®ç°ï¼Œæä¾›äº†ä¸“ä¸šçº§çš„CSVæ–‡ä»¶å¤„ç†èƒ½åŠ›ï¼Œæ”¯æŒä¼ä¸šçº§æ•°æ®ç®¡ç†éœ€æ±‚ï¼** 